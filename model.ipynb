{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize  \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = pd.read_csv(\"Fake.csv\")\n",
    "true = pd.read_csv(\"True.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subject\n",
       "politicsNews       11272\n",
       "worldnews          10145\n",
       "News                9050\n",
       "politics            6841\n",
       "left-news           4459\n",
       "Government News     1570\n",
       "US_News              783\n",
       "Middle-east          778\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true['label']=1\n",
    "fake['label']=0\n",
    "combined = pd.concat([true, fake], ignore_index=True, axis=0)\n",
    "combined.subject.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_news_agency_name(text):\n",
    "    return re.sub(r\"Reuters|AP|New York Times|Washington Post|Business Insider|Atlantic|Fox News|National Review|Talking Points Memo|Buzzfeed News|Guardian|NPR|Vox|CNN|BBC|Bloomberg|Daily Mail\", \"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined['text'] = combined.text.apply(lambda x:x.lower())\n",
    "combined['text'] = combined.text.apply(lambda x:re.sub(r'[^\\w\\s]+', ' ', x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/megsr/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def remove_stopwords(txt):\n",
    "    no_stopwords = [word for word in txt.split() if word not in stop_words]\n",
    "    return ' '.join(no_stopwords)\n",
    "combined['text'] = combined['text'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/megsr/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "combined['text'] = combined.text.apply(lambda x:word_tokenize(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = combined.text.apply(lambda x: ' '.join(x))\n",
    "count_vec = CountVectorizer(stop_words=\"english\", analyzer='word', \n",
    "                            ngram_range=(1, 1), max_df=1.0, min_df=1, max_features=None)\n",
    "count_train = count_vec.fit(txt)\n",
    "bag_of_words = count_vec.transform(txt)\n",
    "features = count_vec.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfidfVectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = combined.text.apply(lambda x: ' '.join(x))\n",
    "tf = TfidfVectorizer(smooth_idf=False, sublinear_tf=False, norm=None, analyzer='word')\n",
    "txt_fitted = tf.fit(txt)\n",
    "txt_transformed = txt_fitted.transform(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression w/ CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error value: 0.06919840105262935\n",
      "accuracy: 0.9952115812917595\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(bag_of_words,combined['label'], test_size=0.2, random_state=42)\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "error_value = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print('error value:',error_value)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('accuracy:',accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression w/ TfidfVectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error value: 0.0768245042570597\n",
      "accuracy: 0.994097995545657\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(txt_transformed,combined['label'], test_size=0.2, random_state=42)\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "error_value = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print('error value:', error_value)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB w/ CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9967706013363029\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(bag_of_words,combined['label'], test_size=0.2, random_state=42)\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_pred = xgb.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, xgb_pred)\n",
    "print('accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB w/ TfidfVectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9974387527839643\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(txt_transformed,combined['label'], test_size=0.2, random_state=42)\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_pred = xgb.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, xgb_pred)\n",
    "print('accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9933184855233853\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(txt_transformed,combined['label'], test_size=0.2, random_state=42)\n",
    "ran = RandomForestClassifier()\n",
    "ran.fit(X_train, y_train)\n",
    "ran_pred = ran.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, ran_pred)\n",
    "print('accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_fake = combined[combined['label']==0]\n",
    "combined_true = combined[combined['label']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('trump', 79300),\n",
       " ('said', 33763),\n",
       " ('president', 27715),\n",
       " ('people', 26570),\n",
       " ('one', 24531)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_d = {}\n",
    "for line in combined_fake.text:\n",
    "    for word in line:\n",
    "        if word in fake_d:\n",
    "                fake_d[word] = fake_d[word] + 1\n",
    "        else:\n",
    "            fake_d[word] = 1\n",
    "Counter(fake_d).most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('said', 99062),\n",
       " ('trump', 54700),\n",
       " ('u', 44570),\n",
       " ('would', 31605),\n",
       " ('reuters', 28976)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_d = {}\n",
    "for line in combined_true.text:\n",
    "    for word in line:\n",
    "        if word in true_d:\n",
    "                true_d[word] = true_d[word] + 1\n",
    "        else:\n",
    "            true_d[word] = 1\n",
    "Counter(true_d).most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = pd.read_csv(\"testing_dataset_v1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelling(col):\n",
    "    if col in ['Inaccurate', 'Misleading', 'Incorrect', 'Unsupported', 'Flawed_Reasoning', 'Imprecise', 'Lacks_Context']:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "testing[\"Label\" ] = testing['Verdict'].apply(lambda x: labelling(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/megsr/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/megsr/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "testing['Claim'] = testing.Claim.apply(lambda x:x.lower())\n",
    "testing['Claim'] = testing.Claim.apply(lambda x:re.sub(r'[^\\w\\s]+', ' ', x))\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def remove_stopwords(txt):\n",
    "    no_stopwords = [word for word in txt.split() if word not in stop_words]\n",
    "    return ' '.join(no_stopwords)\n",
    "testing['Claim'] = testing['Claim'].apply(remove_stopwords)\n",
    "nltk.download('punkt')\n",
    "testing['Claim'] = testing['Claim'].apply(lambda x: ' '.join(word_tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<176x121659 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1946 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_transformed = tf.transform(testing['Claim'])\n",
    "count_vec.transform(testing['Claim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log = model.predict(txt_transformed)\n",
    "log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "0    161\n",
       "1     15\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_name</th>\n",
       "      <th>source_id</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CBC News</td>\n",
       "      <td>cbc-news</td>\n",
       "      <td>2024-01-25T17:08:14Z</td>\n",
       "      <td>Are heat pumps a climate solution in Canada's ...</td>\n",
       "      <td>Our planet is changing. So is our journalism. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CBC News</td>\n",
       "      <td>cbc-news</td>\n",
       "      <td>2024-02-02T17:13:17Z</td>\n",
       "      <td>Greta Thunberg, 4 others acquitted on London c...</td>\n",
       "      <td>A judge on Friday acquitted climate activist G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CBC News</td>\n",
       "      <td>cbc-news</td>\n",
       "      <td>2024-02-01T18:33:06Z</td>\n",
       "      <td>How effective a climate solution is removing C...</td>\n",
       "      <td>Our planet is changing. So is our journalism. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CBC News</td>\n",
       "      <td>cbc-news</td>\n",
       "      <td>2024-01-16T22:39:54Z</td>\n",
       "      <td>YouTube earns millions a year channels that pr...</td>\n",
       "      <td>YouTube is making millions of dollars a year f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CBC News</td>\n",
       "      <td>cbc-news</td>\n",
       "      <td>2024-01-17T09:00:00Z</td>\n",
       "      <td>Climate change threatens northern Ontario's wi...</td>\n",
       "      <td>Tyler Tyance is all too familiar with the long...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Global News</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-02-02T16:14:43Z</td>\n",
       "      <td>Are microplastics harmful? Health Canada funds...</td>\n",
       "      <td>Health Canada is funding new research that wil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Calgary Herald</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-02-08T00:55:51Z</td>\n",
       "      <td>Varcoe: Report warns of $600B hit to Canada ec...</td>\n",
       "      <td>'They are big numbers. And we were trying to m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Calgary Herald</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-01-26T13:50:50Z</td>\n",
       "      <td>Varcoe: Danielle Smith wants to 'double down' ...</td>\n",
       "      <td>There are several major obstacles to significa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ctvnews.ca</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-01-27T03:57:36Z</td>\n",
       "      <td>Amazon: MacKenzie Scott sold US$10B in shares ...</td>\n",
       "      <td>MacKenzie Scott continues to sell billions of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>National Post</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-01-16T23:03:29Z</td>\n",
       "      <td>Jordan Peterson loses fight to avoid mandatory...</td>\n",
       "      <td>Jordan Peterson has failed in his attempt to h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>229 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       source_name source_id          publish_date  \\\n",
       "0         CBC News  cbc-news  2024-01-25T17:08:14Z   \n",
       "1         CBC News  cbc-news  2024-02-02T17:13:17Z   \n",
       "2         CBC News  cbc-news  2024-02-01T18:33:06Z   \n",
       "3         CBC News  cbc-news  2024-01-16T22:39:54Z   \n",
       "4         CBC News  cbc-news  2024-01-17T09:00:00Z   \n",
       "..             ...       ...                   ...   \n",
       "3      Global News       NaN  2024-02-02T16:14:43Z   \n",
       "0   Calgary Herald       NaN  2024-02-08T00:55:51Z   \n",
       "1   Calgary Herald       NaN  2024-01-26T13:50:50Z   \n",
       "0       Ctvnews.ca       NaN  2024-01-27T03:57:36Z   \n",
       "0    National Post       NaN  2024-01-16T23:03:29Z   \n",
       "\n",
       "                                                title  \\\n",
       "0   Are heat pumps a climate solution in Canada's ...   \n",
       "1   Greta Thunberg, 4 others acquitted on London c...   \n",
       "2   How effective a climate solution is removing C...   \n",
       "3   YouTube earns millions a year channels that pr...   \n",
       "4   Climate change threatens northern Ontario's wi...   \n",
       "..                                                ...   \n",
       "3   Are microplastics harmful? Health Canada funds...   \n",
       "0   Varcoe: Report warns of $600B hit to Canada ec...   \n",
       "1   Varcoe: Danielle Smith wants to 'double down' ...   \n",
       "0   Amazon: MacKenzie Scott sold US$10B in shares ...   \n",
       "0   Jordan Peterson loses fight to avoid mandatory...   \n",
       "\n",
       "                                                 text  \n",
       "0   Our planet is changing. So is our journalism. ...  \n",
       "1   A judge on Friday acquitted climate activist G...  \n",
       "2   Our planet is changing. So is our journalism. ...  \n",
       "3   YouTube is making millions of dollars a year f...  \n",
       "4   Tyler Tyance is all too familiar with the long...  \n",
       "..                                                ...  \n",
       "3   Health Canada is funding new research that wil...  \n",
       "0   'They are big numbers. And we were trying to m...  \n",
       "1   There are several major obstacles to significa...  \n",
       "0   MacKenzie Scott continues to sell billions of ...  \n",
       "0   Jordan Peterson has failed in his attempt to h...  \n",
       "\n",
       "[229 rows x 5 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api = pd.read_csv(\"all_sources_resDf.csv\", index_col= 0)\n",
    "api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/megsr/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/megsr/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    planet changing journalism weekly newsletter p...\n",
       "1    judge friday acquitted climate activist greta ...\n",
       "2    planet changing journalism weekly newsletter p...\n",
       "3    youtube making millions dollars year advertisi...\n",
       "4    tyler tyance familiar long days cold nights da...\n",
       "                           ...                        \n",
       "3    health canada funding new research look potent...\n",
       "0    big numbers trying make case ottawa alberta we...\n",
       "1    several major obstacles significantly hike out...\n",
       "0    mackenzie scott continues sell billions dollar...\n",
       "0    jordan peterson failed attempt ontario court s...\n",
       "Name: text, Length: 229, dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api['text'] = api.text.apply(lambda x:str(x))\n",
    "api['text'] = api.text.apply(lambda x:x.lower())\n",
    "api['text'] = api.text.apply(lambda x:re.sub(r'[^\\w\\s]+', ' ', x))\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def remove_stopwords(txt):\n",
    "    no_stopwords = [word for word in txt.split() if word not in stop_words]\n",
    "    return ' '.join(no_stopwords)\n",
    "api['text'] = api['text'].apply(remove_stopwords)\n",
    "nltk.download('punkt')\n",
    "api['text'] = api['text'].apply(lambda x: ' '.join(word_tokenize(x)))\n",
    "api.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_transformed = tf.transform(api['text'])\n",
    "arr = ran.predict(txt_transformed)\n",
    "blah = list(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_name</th>\n",
       "      <th>source_id</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>random_forest_results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CBC News</td>\n",
       "      <td>cbc-news</td>\n",
       "      <td>2024-02-08T12:55:13Z</td>\n",
       "      <td>World temperatures go a full year above 1.5 C ...</td>\n",
       "      <td>world experienced hottest january record conti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>CBC News</td>\n",
       "      <td>cbc-news</td>\n",
       "      <td>2024-02-09T14:49:00Z</td>\n",
       "      <td>Candidates backed by imprisoned former PM Imra...</td>\n",
       "      <td>independent candidates backed imprisoned forme...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>CBC News</td>\n",
       "      <td>cbc-news</td>\n",
       "      <td>2024-01-29T20:41:30Z</td>\n",
       "      <td>Top Liberal ministers duck questions about rep...</td>\n",
       "      <td>polls suggesting liberal party support still f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>CBC News</td>\n",
       "      <td>cbc-news</td>\n",
       "      <td>2024-01-25T04:35:00Z</td>\n",
       "      <td>Vancouver council approves policy statement fo...</td>\n",
       "      <td>indigenous led proposal build mixed use develo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CBC News</td>\n",
       "      <td>cbc-news</td>\n",
       "      <td>2024-02-08T12:55:13Z</td>\n",
       "      <td>World temperatures go a full year above 1.5 C ...</td>\n",
       "      <td>world experienced hottest january record conti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>CBC News</td>\n",
       "      <td>cbc-news</td>\n",
       "      <td>2024-02-09T14:49:00Z</td>\n",
       "      <td>Candidates backed by imprisoned former PM Imra...</td>\n",
       "      <td>independent candidates backed imprisoned forme...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>CBC News</td>\n",
       "      <td>cbc-news</td>\n",
       "      <td>2024-01-29T20:41:30Z</td>\n",
       "      <td>Top Liberal ministers duck questions about rep...</td>\n",
       "      <td>polls suggesting liberal party support still f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>CBC News</td>\n",
       "      <td>cbc-news</td>\n",
       "      <td>2024-01-25T04:35:00Z</td>\n",
       "      <td>Vancouver council approves policy statement fo...</td>\n",
       "      <td>indigenous led proposal build mixed use develo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source_name source_id          publish_date  \\\n",
       "14    CBC News  cbc-news  2024-02-08T12:55:13Z   \n",
       "20    CBC News  cbc-news  2024-02-09T14:49:00Z   \n",
       "22    CBC News  cbc-news  2024-01-29T20:41:30Z   \n",
       "82    CBC News  cbc-news  2024-01-25T04:35:00Z   \n",
       "14    CBC News  cbc-news  2024-02-08T12:55:13Z   \n",
       "20    CBC News  cbc-news  2024-02-09T14:49:00Z   \n",
       "22    CBC News  cbc-news  2024-01-29T20:41:30Z   \n",
       "82    CBC News  cbc-news  2024-01-25T04:35:00Z   \n",
       "\n",
       "                                                title  \\\n",
       "14  World temperatures go a full year above 1.5 C ...   \n",
       "20  Candidates backed by imprisoned former PM Imra...   \n",
       "22  Top Liberal ministers duck questions about rep...   \n",
       "82  Vancouver council approves policy statement fo...   \n",
       "14  World temperatures go a full year above 1.5 C ...   \n",
       "20  Candidates backed by imprisoned former PM Imra...   \n",
       "22  Top Liberal ministers duck questions about rep...   \n",
       "82  Vancouver council approves policy statement fo...   \n",
       "\n",
       "                                                 text  random_forest_results  \n",
       "14  world experienced hottest january record conti...                      1  \n",
       "20  independent candidates backed imprisoned forme...                      1  \n",
       "22  polls suggesting liberal party support still f...                      1  \n",
       "82  indigenous led proposal build mixed use develo...                      1  \n",
       "14  world experienced hottest january record conti...                      1  \n",
       "20  independent candidates backed imprisoned forme...                      1  \n",
       "22  polls suggesting liberal party support still f...                      1  \n",
       "82  indigenous led proposal build mixed use develo...                      1  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api['random_forest_results']=blah\n",
    "api[api['random_forest_results']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source_name\n",
       "CBC News              200\n",
       "Financial Post         19\n",
       "Global News             4\n",
       "Calgary Herald          2\n",
       "The Globe And Mail      1\n",
       "Ctvnews.ca              1\n",
       "National Post           1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api.source_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_transformed = tf.transform(testing['Claim'])\n",
    "arr = ran.predict(txt_transformed)\n",
    "arr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
